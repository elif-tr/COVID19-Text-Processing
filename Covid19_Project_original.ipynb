{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "Covid19-Project_original.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elif-tr/COVID19-Text-Processing/blob/main/Covid19_Project_original.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX15tGzaRRKt"
      },
      "source": [
        "## COVID19 related papers that published during the first week of May, 2020"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jwSShsgRRKt",
        "outputId": "8d1ce1f2-350d-4906-a67e-e31e2e117c15"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/elif/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAPhsvcBRRKx"
      },
      "source": [
        "### Define a global variable for the folder name that contains the json files of the papers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmVrSKx1RRKx"
      },
      "source": [
        "DATA_DIR = 'archive (1)'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xrp7YeuoRRK0"
      },
      "source": [
        "### Working with meta data file\n",
        "\n",
        "First read in the meta data file to filter the papers for the time frame we want."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dD0Up0cYRRK0"
      },
      "source": [
        "def meta_data(folder_name, metadata = \"metadata.csv\"):\n",
        "    ''' Function that takes in the folder name and returns the data fram fro the meta data\n",
        "    \n",
        "    :param folder_name: name of folder where covid data is located\n",
        "    :param metadata: file name for where metadata is saved\n",
        "    :return: data frame of the metadata\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    file_name = os.path.join(os.getcwd(),folder_name, metadata )\n",
        "    data = pd.read_csv((file_name), usecols=['pdf_json_files', 'publish_time'])\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-jKpH8sRRK2"
      },
      "source": [
        "def json_files(start_date = '2020-05-01', end_date = '2020-05-07'):\n",
        "    '''Function that filters the meta data file for a time frame we want. \n",
        "    If nothing specified, first week of may will be used\n",
        "    \n",
        "    :param start_date: reading in the json files from when they were published \n",
        "    :param end_date: reading in the json files until when they were published \n",
        "    :return: lisf of json file names that are within the specified publication date\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    global DATA_DIR\n",
        "    \n",
        "    file = meta_data(DATA_DIR)\n",
        "    file['publication_date'] = pd.to_datetime(file['publish_time'])\n",
        "    may_first_week = file[(file['publication_date'] > start_date) & (file['publication_date'] <= end_date)]\n",
        "    \n",
        "    return list(may_first_week['pdf_json_files'].dropna())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY7KQzkzRRK4"
      },
      "source": [
        "### Files that contain multiple papers\n",
        "\n",
        "I observed that some of the files contain more than one paper which makes it harder for us to read them in individually. For that, we will bring all our json files into same format of containing 1 file per document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEcSZoYtRRK5"
      },
      "source": [
        "#Those files were separated by ; sign instead of , sign.\n",
        "\n",
        "all_files = []\n",
        "for file in json_files():\n",
        "    all_files.extend(map(str.strip, file.split(\";\")))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YlIxdLERRK7"
      },
      "source": [
        "### Extracting only the columns needed for our analysis \n",
        "\n",
        "Some of the code was take from: https://www.kaggle.com/davidbetancur8/symptoms-word-cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpJwQomPRRK7"
      },
      "source": [
        "def read_json_files(file_list = all_files):\n",
        "    \n",
        "    '''Function that takes in date filtered json files and outputs a data frame with only 3 columns: paper_id, title and body text of the paper\n",
        "    \n",
        "    :param file_list: list of json files that will be read in by locating in the directory \n",
        "    :return: return a data frame of those json files with three columns only \"paper_id\", \"title\", \"full_text\"\n",
        "    \n",
        "    '''\n",
        "    docs = []\n",
        "    for file in file_list:\n",
        "        file_name = os.path.join(os.getcwd(),DATA_DIR, file)\n",
        "        with open(file_name) as f:\n",
        "            data_json = json.load(f)\n",
        "                        \n",
        "            \n",
        "        title = data_json[\"metadata\"][\"title\"]\n",
        "        paper_id = data_json['paper_id']\n",
        "        \n",
        "\n",
        "        full_text = \"\"\n",
        "        i = 1\n",
        "        for text in data_json[\"body_text\"]:\n",
        "            i+=1\n",
        "            full_text += text[\"text\"].lower()\n",
        "        docs.append([paper_id, title, full_text])\n",
        "\n",
        "    df = pd.DataFrame(docs, columns=[\"paper_id\", \"title\", \"full_text\"])\n",
        "\n",
        "    return df\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S99UAX8LRRK-"
      },
      "source": [
        "### Extracting sentences that contain systoms "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPZSR_SARRK-"
      },
      "source": [
        "Defining the symptoms that we will extract from our sentences. The list was taken from: https://www.kaggle.com/davidbetancur8/symptoms-word-cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H4OMYLcRRK_"
      },
      "source": [
        "symptoms = [\n",
        "    \"weight loss\",\"chills\",\"shivering\",\"convulsions\",\"deformity\",\"discharge\",\"dizziness\",\n",
        "    \"vertigo\",\"fatigue\",\"malaise\",\"asthenia\",\"hypothermia\",\"jaundice\",\"muscle weakness\",\n",
        "    \"pyrexia\",\"sweats\",\"swelling\",\"swollen\",\"painful lymph node\",\"weight gain\",\"arrhythmia\",\n",
        "    \"bradycardia\",\"chest pain\",\"claudication\",\"palpitations\",\"tachycardia\",\"dry mouth\",\"epistaxis\",\n",
        "    \"halitosis\",\"hearing loss\",\"nasal discharge\",\"otalgia\",\"otorrhea\",\"sore throat\",\"toothache\",\"tinnitus\",\n",
        "    \"trismus\",\"abdominal pain\",\"fever\",\"bloating\",\"belching\",\"bleeding\",\"blood in stool\",\"melena\",\"hematochezia\",\n",
        "    \"constipation\",\"diarrhea\",\"dysphagia\",\"dyspepsia\",\"fecal incontinence\",\"flatulence\",\"heartburn\",\n",
        "    \"nausea\",\"odynophagia\",\"proctalgia fugax\",\"pyrosis\",\"steatorrhea\",\"vomiting\",\"alopecia\",\"hirsutism\",\n",
        "    \"hypertrichosis\",\"abrasion\",\"anasarca\",\"bleeding into the skin\",\"petechia\",\"purpura\",\"ecchymosis and bruising\",\n",
        "    \"blister\",\"edema\",\"itching\",\"laceration\",\"rash\",\"urticaria\",\"abnormal posturing\",\"acalculia\",\"agnosia\",\"alexia\",\n",
        "    \"amnesia\",\"anomia\",\"anosognosia\",\"aphasia and apraxia\",\"apraxia\",\"ataxia\",\"cataplexy\",\"confusion\",\"dysarthria\",\n",
        "    \"dysdiadochokinesia\",\"dysgraphia\",\"hallucination\",\"headache\",\"akinesia\",\"bradykinesia\",\"akathisia\",\"athetosis\",\n",
        "    \"ballismus\",\"blepharospasm\",\"chorea\",\"dystonia\",\"fasciculation\",\"muscle cramps\",\"myoclonus\",\"opsoclonus\",\n",
        "    \"tremor\",\"flapping tremor\",\"insomnia\",\"loss of consciousness\",\"syncope\",\"neck stiffness\",\"opisthotonus\",\n",
        "    \"paralysis and paresis\",\"paresthesia\",\"prosopagnosia\",\"somnolence\",\"abnormal vaginal bleeding\",\n",
        "    \"vaginal bleeding in early pregnancy\", \"miscarriage\",\"vaginal bleeding in late pregnancy\",\"amenorrhea\",\n",
        "    \"infertility\",\"painful intercourse\",\"pelvic pain\",\"vaginal discharge\",\"amaurosis fugax\",\"amaurosis\",\n",
        "    \"blurred vision\",\"double vision\",\"exophthalmos\",\"mydriasis\",\"miosis\",\"nystagmus\",\"amusia\",\"anhedonia\",\n",
        "    \"anxiety\",\"apathy\",\"confabulation\",\"depression\",\"delusion\",\"euphoria\",\"homicidal ideation\",\"irritability\",\n",
        "    \"mania\",\"paranoid ideation\",\"suicidal ideation\",\"apnea\",\"hypopnea\",\"cough\",\"dyspnea\",\"bradypnea\",\"tachypnea\",\n",
        "    \"orthopnea\",\"platypnea\",\"trepopnea\",\"hemoptysis\",\"pleuritic chest pain\",\"sputum production\",\"arthralgia\",\n",
        "    \"back pain\",\"sciatica\",\"Urologic\",\"dysuria\",\"hematospermia\",\"hematuria\",\"impotence\",\"polyuria\",\n",
        "    \"retrograde ejaculation\",\"strangury\",\"urethral discharge\",\"urinary frequency\",\"urinary incontinence\",\"urinary retention\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZkKuGzfRRLB"
      },
      "source": [
        "## Check the papers that contain the words in  our list of symptoms and then we will extract those sentences only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iP0WdTQRRLB"
      },
      "source": [
        "I had to create a seperate data frame without the title column to work on as it kept getting mixed with the full text when using nltk.tokenize. \n",
        "\n",
        "I spent quite long time on this figure out why it was happening therefore, decided to use the data frame with paper id and fulltext only."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-_FDh_ZRRLC"
      },
      "source": [
        "data_frame = read_json_files()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2Z1xdX5RRLE"
      },
      "source": [
        "df_no_title = data_frame[['paper_id', 'full_text']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiGxCutURRLG"
      },
      "source": [
        "## nltk.tokenize\n",
        "\n",
        "I used nltk.tokenize to split the full text into one sentence per row"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pjWfnZ8RRLG"
      },
      "source": [
        "sentences = []\n",
        "for row in df_no_title.itertuples():            \n",
        "     for sentence in sent_tokenize(row[2]):\n",
        "            sentences.append((row[1], sentence))\n",
        "    \n",
        "new_df = pd.DataFrame(sentences, columns=['Paper_Id', 'Sentence'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-QZ6DLtRRLI"
      },
      "source": [
        "\n",
        "Added in the Sentence ID column to keep track of which sentences will be retreived when we check for the symptoms in each sentence. Started the id values from 1 thus the increment of 1 on the existing data frame index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trybbRQfRRLJ"
      },
      "source": [
        "new_df['Sentence_ID'] = new_df.index + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHaDTzPaRRLL",
        "outputId": "52616d31-473f-47e2-e3f6-6d970233886c"
      },
      "source": [
        "new_df['Sentence'][108]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fifty-two patients had a severe hypercapnia with a p aco2 â‰¥ 60 mmhg and 28 a severe acidosis with a ph < 7.2. all subjects were sedated and invasive mechanically ventilated in a pressure controlled mode with a shorter duration before pecla in the survivor group.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvPkDzxGRRLP"
      },
      "source": [
        "### Final data frame that only includes sentences from each text that contains any of the symptoms from our list of symptoms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5S2oraiRRLQ"
      },
      "source": [
        "final_df = new_df[new_df['Sentence'].str.contains('|'.join(symptoms))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9tafjiGRRLS",
        "outputId": "626b96bf-10e4-4398-eb9c-f7d59a12ef29"
      },
      "source": [
        "final_df['Sentence'].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "112    11% died due to infaust neurologic prognosis (...\n",
              "259    we retrospectively analyzed medical charts of ...\n",
              "260    the patient first had 4-5 episodes of watery d...\n",
              "261    she was given intravenous (iv) fluids and disc...\n",
              "262    however, she returned to the ed the next day w...\n",
              "Name: Sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRhbsVtaRRLU"
      },
      "source": [
        "### Rearranged the display of the columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9OhDqQxRRLU"
      },
      "source": [
        "columnsTitles = ['Paper_Id', 'Sentence_ID', 'Sentence']\n",
        "\n",
        "covid_df = final_df.reindex(columns=columnsTitles)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Vw-ghhBRRLX"
      },
      "source": [
        "### Save the sentences in a csv file where there are 3 columns: paper ID, sentence ID, and sentence text to be our testing data.\n",
        "\n",
        "I did not save the indexes as it would create multiple index columns when we reread in the file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ca-HkGalRRLX"
      },
      "source": [
        "covid_df.to_csv('/Users/elif/Desktop/covid_testing_data.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybr2P-RFRRLZ"
      },
      "source": [
        "###   Create another spreadsheet where there are three columns: sentence #, word, and tag. \n",
        "### Here the sentence # should be consecutive integers (similar to a surrogate key in a database table) and is not the same as sentence ID in the first spreadsheet.\n",
        "\n",
        "\n",
        "    Place one word in a row and label symptoms words in the tag column: \n",
        "    mark the beginning (B-Sym) and inside (I-Sym) of each symptom term. \n",
        "    If a term consists of only one word, simply mark it as B-Sym with no I-Sym.  \n",
        "    Label all other words as O. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4Onro1FRRLZ"
      },
      "source": [
        "frame = final_df[['Sentence']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hW3MHNAxRRLb",
        "outputId": "20d22055-1eb7-4c83-dc93-c87218cf0992"
      },
      "source": [
        "frame.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>11% died due to infaust neurologic prognosis (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>we retrospectively analyzed medical charts of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>the patient first had 4-5 episodes of watery d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>she was given intravenous (iv) fluids and disc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>however, she returned to the ed the next day w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Sentence\n",
              "112  11% died due to infaust neurologic prognosis (...\n",
              "259  we retrospectively analyzed medical charts of ...\n",
              "260  the patient first had 4-5 episodes of watery d...\n",
              "261  she was given intravenous (iv) fluids and disc...\n",
              "262  however, she returned to the ed the next day w..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FaIyDkiRRLd"
      },
      "source": [
        "### Tokenize sentences\n",
        "\n",
        "In this part of the task, I tried using string comparison but could not get it to work in my code or got stuck with labeling again. \n",
        "\n",
        "Instead, I went over my head and tried to use regular expressions to do the tagging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4PAz8bARRLd"
      },
      "source": [
        "#Create a pattern for regex and use it with nltk.tagger to tag the symptoms \n",
        "pattern = [(symptom, ' '.join(['B-SYM']+['I-SYM']*(symptom.count(' '))))  for symptom in symptoms]\n",
        "tagger = nltk.RegexpTagger(pattern)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmF9ELVORRLf"
      },
      "source": [
        "words = []\n",
        "for row in frame.itertuples():            \n",
        "    for word, tag in tagger.tag(word_tokenize(row[1])):\n",
        "\n",
        "        if tag == None:\n",
        "            tag = 'O'\n",
        "        words.append((row[0], word, tag))\n",
        "    \n",
        "tag_df = pd.DataFrame(words, columns=['Sentence', 'Words', 'Tag'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReioAQSvRRLg"
      },
      "source": [
        "    - Cheking the words to tag them according to the tags we have on the provided excel sheet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aseZE48ARRLh"
      },
      "source": [
        "    - Above tagging is working however, I need to identify the symptoms that come from multiple words..\n",
        "    \n",
        "    I am stuck here.\n",
        "    \n",
        "I observed that there are 43 multiple word symptoms and 375 rows that contain multiple word symptoms that I need to indetify."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EbVPsvLRRLi"
      },
      "source": [
        "#Styling of sentence numbers ~ instead of duplicating the same number over and over again,\n",
        "#we leave out the duplicated ones by replacing them with space\n",
        "tag_df['Sentence_ID'] = tag_df['Sentence']\n",
        "is_duplicate = tag_df['Sentence'].duplicated()\n",
        "\n",
        "tag_df['Sentence_ID'] = tag_df['Sentence'].where(~is_duplicate, ' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPQYwGQfRRLk"
      },
      "source": [
        "tagged_data = tag_df[['Sentence_ID', 'Words', 'Tag']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTrk_vVpRRLl"
      },
      "source": [
        "tagged_data.to_csv('/Users/elif/Desktop/covid_tagged_data.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0Vmw0nVRRLo"
      },
      "source": [
        "## THANK YOU!"
      ]
    }
  ]
}